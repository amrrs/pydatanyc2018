{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyData 2018 NYC: End to End Data Science Without Leaving the GPU\n",
    "\n",
    "Randy Zwitch <br>\n",
    "Senior Developer Advocate, [OmniSci](https://omnisci.com) (formerly MapD) <br>\n",
    "October 18, 2018\n",
    "\n",
    "Twitter: [@randyzwitch](https://twitter.com/randyzwitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- Personal Introduction\n",
    "- What is OmniSci? (Also...we're hiring!)\n",
    "- GOAI/RAPIDS\n",
    "- Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Source data stored in OmniSci GPU database\n",
    "\n",
    "As the starting point for our \"End to End\" journey, the data are stored in OmniSci, a GPU-accelerated relation database and analytics platform. The data are hourly measurements of electricity demand in the PJM Interconnection transmission area from 1993-01-01 to present. (Brief OmniSci demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Foo](omnisci_screenshot.png)](http://13.90.129.165:9092/#/dashboard/49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connecting to OmniSci via Python\n",
    "\n",
    "OmniSci is part of the [GPU Open Analytics Initiative](http://gpuopenanalytics.com/#/), with the mission of allowing a data scientist to \"explore data, train machine learning algorithms, and build applications while primarily staying on the GPU\". The foundation of this workflow is the [GPU Dataframe](https://github.com/rapidsai/libgdf), which OmniSci supports returning results in when using [pymapd](https://github.com/omnisci/pymapd).\n",
    "\n",
    "GOAI is an idealized state and very much a work-in-progress. As such, it is _possible_ to do an end-to-end workflow without ever leaving the GPU. However, in the case of this tutorial, I have worked around some gaps in functionality by copying the data from one GPU to another one with the desired properties. Eventually, these edges will be smoothed out, providing a seamless workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mapdadmin/miniconda3/envs/pydatacupy/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/mapdadmin/miniconda3/envs/pydatacupy/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#pymapd native connector to OmniSci\n",
    "#numpy.dtype warning a cython issue, safe to ignore\n",
    "import pymapd\n",
    "import pandas as pd\n",
    "from pygdf.dataframe import DataFrame\n",
    "from credentials import password, user, database #user needs to define themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_beginning_utc</th>\n",
       "      <th>datetime_beginning_ept</th>\n",
       "      <th>nerc_region</th>\n",
       "      <th>mkt_region</th>\n",
       "      <th>zone</th>\n",
       "      <th>load_area</th>\n",
       "      <th>mw</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993-02-13 15:00:00</td>\n",
       "      <td>1993-02-13 10:00:00</td>\n",
       "      <td>PJM RTO</td>\n",
       "      <td>PJM</td>\n",
       "      <td>PS</td>\n",
       "      <td>PS</td>\n",
       "      <td>4605</td>\n",
       "      <td>1</td>\n",
       "      <td>1993-02-13 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993-03-26 10:00:00</td>\n",
       "      <td>1993-03-26 05:00:00</td>\n",
       "      <td>PJM RTO</td>\n",
       "      <td>PJM</td>\n",
       "      <td>CNCT</td>\n",
       "      <td>DPL</td>\n",
       "      <td>1391</td>\n",
       "      <td>1</td>\n",
       "      <td>1993-03-26 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-01-18 00:00:00</td>\n",
       "      <td>1993-01-17 19:00:00</td>\n",
       "      <td>PJM RTO</td>\n",
       "      <td>PJM</td>\n",
       "      <td>PEP</td>\n",
       "      <td>PEPCO</td>\n",
       "      <td>2981</td>\n",
       "      <td>1</td>\n",
       "      <td>1993-01-17 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-01-16 20:00:00</td>\n",
       "      <td>1993-01-16 15:00:00</td>\n",
       "      <td>PJM RTO</td>\n",
       "      <td>PJM</td>\n",
       "      <td>PL</td>\n",
       "      <td>UGI</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1993-01-16 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-07-19 23:00:00</td>\n",
       "      <td>1993-07-19 19:00:00</td>\n",
       "      <td>PJM RTO</td>\n",
       "      <td>PJM</td>\n",
       "      <td>GPU</td>\n",
       "      <td>ME</td>\n",
       "      <td>1423</td>\n",
       "      <td>1</td>\n",
       "      <td>1993-07-19 19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_beginning_utc datetime_beginning_ept nerc_region mkt_region  zone  \\\n",
       "0    1993-02-13 15:00:00    1993-02-13 10:00:00     PJM RTO        PJM    PS   \n",
       "1    1993-03-26 10:00:00    1993-03-26 05:00:00     PJM RTO        PJM  CNCT   \n",
       "2    1993-01-18 00:00:00    1993-01-17 19:00:00     PJM RTO        PJM   PEP   \n",
       "3    1993-01-16 20:00:00    1993-01-16 15:00:00     PJM RTO        PJM    PL   \n",
       "4    1993-07-19 23:00:00    1993-07-19 19:00:00     PJM RTO        PJM   GPU   \n",
       "\n",
       "  load_area    mw  is_verified                  idx  \n",
       "0        PS  4605            1  1993-02-13 10:00:00  \n",
       "1       DPL  1391            1  1993-03-26 05:00:00  \n",
       "2     PEPCO  2981            1  1993-01-17 19:00:00  \n",
       "3       UGI   120            1  1993-01-16 15:00:00  \n",
       "4        ME  1423            1  1993-07-19 19:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect using Ibis (which in turn, uses pymapd behind the scenes)\n",
    "conn = pymapd.connect(host = \"localhost\", port = 9091, password = password, dbname = database, user = user) \n",
    "\n",
    "#show sample of data\n",
    "#pymapd is DBI-compliant, so you can pass a query string to pandas\n",
    "#passing through pandas causes a CPU copy, which is ok because I'm using pandas for pretty-printing\n",
    "pd.read_sql(\"select * from hrl_load_metered limit 5\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pulling Data Sample\n",
    "\n",
    "In order to build a simple model forecasting electricity demand, we need to get the data from OmniSci into Python. While we're pulling the data, we can define a few features like day of week, month, hour and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mapdadmin/.local/lib/python3.5/site-packages/pyarrow/util.py:35: FutureWarning: pyarrow.frombuffer is deprecated as of 0.9.0, please use py_buffer instead\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_beginning_ept</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month_</th>\n",
       "      <th>hour_</th>\n",
       "      <th>year_</th>\n",
       "      <th>mw</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-07-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>83692</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-07-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>78211</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-07-01 02:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>74585</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-07-01 03:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>72095</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-07-01 04:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>71461</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_beginning_ept  day_of_week  month_  hour_  year_     mw  intercept\n",
       "0    2005-07-01 00:00:00            5       7      0   2005  83692        1.0\n",
       "1    2005-07-01 01:00:00            5       7      1   2005  78211        1.0\n",
       "2    2005-07-01 02:00:00            5       7      2   2005  74585        1.0\n",
       "3    2005-07-01 03:00:00            5       7      3   2005  72095        1.0\n",
       "4    2005-07-01 04:00:00            5       7      4   2005  71461        1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Limiting data to more recent years based on domain knowledge\n",
    "#Definition of 'RTO' area grew considerably in early 2000s, definition stabilized around then\n",
    "df = conn.select_ipc(\"\"\"select\n",
    "datetime_beginning_ept,\n",
    "extract(DOW from datetime_beginning_ept) as day_of_week,\n",
    "extract(MONTH from datetime_beginning_ept) as month_,\n",
    "extract(HOUR from datetime_beginning_ept) as hour_,\n",
    "extract(YEAR from datetime_beginning_ept) as year_,\n",
    "mw,\n",
    "cast(1 as double) as intercept\n",
    "from hrl_load_metered\n",
    "where zone = 'RTO' and datetime_beginning_ept >= '2005-07-01 00:00:00'\n",
    "order by 1\n",
    "\"\"\")\n",
    "\n",
    "#DataFrame.from_pandas() a work-around for https://github.com/rapidsai/pygdf/issues/286\n",
    "rto_demand_gdf = DataFrame.from_pandas(df)\n",
    "\n",
    "#pretty printing\n",
    "rto_demand_gdf.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Curve Fitting Using Linear Regression\n",
    "\n",
    "From the crossfiltering demonstration using Immerse, as well as the heatmap, we can see that electricity demand is well described just by knowing the time of day and day of the week. We can validate this hypothesis using linear regression. \n",
    "\n",
    "Because the data are already on the GPU, and since the math of linear regression can be represented in basic linear algebra terms, we'll do that instead of using a machine learning library. Instead, we'll use [CuPy](https://cupy.chainer.org/) to get the coefficients and validate the model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. One-hot encoding for day of week, month, hour, year\n",
    "\n",
    "Although month and day of the week are stored as numbers, we don't want to use them that way. Rather, we create 1/0 variables using the `gdf.one_hot_encoding()` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_beginning_ept</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month_</th>\n",
       "      <th>hour_</th>\n",
       "      <th>year_</th>\n",
       "      <th>mw</th>\n",
       "      <th>intercept</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-07-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>83692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-07-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>78211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-07-01 02:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>74585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-07-01 03:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>72095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-07-01 04:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>71461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_beginning_ept  day_of_week  month_  hour_  year_     mw  intercept  \\\n",
       "0    2005-07-01 00:00:00            5       7      0   2005  83692        1.0   \n",
       "1    2005-07-01 01:00:00            5       7      1   2005  78211        1.0   \n",
       "2    2005-07-01 02:00:00            5       7      2   2005  74585        1.0   \n",
       "3    2005-07-01 03:00:00            5       7      3   2005  72095        1.0   \n",
       "4    2005-07-01 04:00:00            5       7      4   2005  71461        1.0   \n",
       "\n",
       "   dow_0  dow_1  dow_2   ...     hour_13  hour_14  hour_15  hour_16  hour_17  \\\n",
       "0    0.0    0.0    0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "1    0.0    0.0    0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "2    0.0    0.0    0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "3    0.0    0.0    0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "4    0.0    0.0    0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   hour_18  hour_19  hour_20  hour_21  hour_22  \n",
       "0      0.0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do one-hot encoding on day of week and month\n",
    "rto_demand_gdf_1 = rto_demand_gdf.one_hot_encoding('day_of_week', 'dow', range(0,6))\n",
    "rto_demand_gdf_2 = rto_demand_gdf_1.one_hot_encoding('month_', 'month', range(1,12))\n",
    "rto_demand_gdf_encoded = rto_demand_gdf_2.one_hot_encoding('hour_', 'hour', range(0,23))\n",
    "\n",
    "# pretty printing\n",
    "rto_demand_gdf_encoded.head().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pygdf.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rto_demand_gdf_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Split into training, validation sets\n",
    "\n",
    "Since this is a time-series problem, we'll estimate our model based on a given set of years, then test it against future years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On-GPU processing\n",
    "train = rto_demand_gdf_encoded.query('year_ <= 2016')\n",
    "val = rto_demand_gdf_encoded.query('year_ > 2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "from cupy import asarray, dot\n",
    "from cupy.linalg import inv, qr\n",
    "\n",
    "#list of predictors\n",
    "indep = list(train.columns)[6:]\n",
    "\n",
    "#Predictor matrix: convert to cupy.core.core.ndarray (numpy array on GPU)\n",
    "X_train = asarray(train.loc[:, indep].as_matrix())\n",
    "X_val = asarray(val.loc[:, indep].as_matrix())\n",
    "\n",
    "#Target matrix: convert to cupy.core.core.ndarray (numpy array on GPU)\n",
    "y_train = asarray(train.loc[:, ['mw']].as_matrix())\n",
    "y_val = asarray(val.loc[:, ['mw']].as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Calculate model parameters using CuPy and Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 µs ± 23.7 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#use timeit to highlight speed of GPU calculation\n",
    "#linear regression generally not calculated this way, because taking inverse computationally expensive\n",
    "%timeit inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model coefficients (timeit doesn't save results)\n",
    "coef = inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted values on GPU\n",
    "yhat_train = X_train.dot(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(10247.56041388)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate RMSE on GPU\n",
    "rmse = cupy.sqrt(cupy.sum(cupy.square(yhat_train - y_train)) / len(y_train))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MAPE on GPU\n",
    "mape = cupy.mean(cupy.abs((y_train - yhat_train) / y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.09246984)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9.2% error not bad for such simplistic model, validation sample likely worse\n",
    "mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Model Performance\n",
    "\n",
    "pymapd provides a method `render_vega` that can be used to render data on the GPU (this is the basis of how the Immerse interface works). Additionally, we can upload the data back into OmniSci and build an Immerse dashboard.\n",
    "\n",
    "For this example, we'll just use local CPU rendering since the data are modest in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = pd.DataFrame(cupy.concatenate((yhat_train, y_train), axis=1).get(), columns=[\"forecasted\", \"actual\"])\n",
    "lc.index = train[\"datetime_beginning_ept\"].to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "data = lc.loc[(lc.index >= '2016-10-01 00:00:00') & (lc.index < '2016-11-01 00:00:00')]\n",
    "p = data.plot(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Future: GOAI and RAPIDS...GPUing ALL THE THINGS!\n",
    "\n",
    "With the adoption of Apache Arrow as the common data format between tool, huge strides have already been made towards the goal of a fully end-to-end GPU analytics and machine learning pipeline.\n",
    "\n",
    "\n",
    "To learn more, visit the following links:\n",
    "\n",
    "[GPU Open Analytics Initiative](http://gpuopenanalytics.com)\n",
    "\n",
    "[RAPIDS](https://rapids.ai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
